[PROCESS]
experiment_ID: L${NETWORK:num_layers}_H${NETWORK:layer_size}_DO${TRAINING:dropout_keep_probability}_L1${TRAINING:l1_regularization}_L2${TRAINING:l2_regularization}_B${TRAINING:batch_size}_LR${TRAINING:learning_rate} #empty means auto name
checkpoint_every: 10000 # in number of iterations
validation_interval: 20 # in number of iterations, default if omitted:15
initialize_with_checkpoint: # path like: checkpoints/enigma/training.ckpt-10


[PATHS]
training_file: data/train_uniq.csv
validation_file: data/enigma_validation_sex(age).csv
checkpoint_dir: checkpoints/enigma
log_folder: log/sexage


[NETWORK]
num_layers: 2
layer_size: 32  #previously "number of hidden units"
residual: True #default: False

[FEATURES]
columns: 0:-1


[TASK0] #name of section has to begin with TASK
type: classification
ground_truth_column: -1 #-1 for last column
num_classes: 2
weight: 1 #loss weight, how important is task compared to other tasks


#[TASK1] #This task is commented out
#type: linear
#ground_truth_column: -1


[TRAINING]
num_epochs: 1000 #set to 0 to do no training
learning_rate: 0.001
batch_size: 64
validation_batch_size: 600
optimizer: adam #one of [vanilla, adam, adagrad, rmsprop]
l1_regularization: 0.01 #default if omitted : 0
l2_regularization: 0.01 #default if omitted : 0
dropout_keep_probability: 0.5 #default if omitted : 1
stratified_sampling: TASK0
#Optional, if specified , makes batching do weighted sampling on input data ,
#such as all classes are represented equally during training.
#Value must specifiy a classification task's name, e.g. TASK0

[TEST]
#optional. To omit testing , please remove the whole [TEST] section
#Testing will always happen after all training epochs are done
test_file:  data/enigma_test_sex(age).csv
write_predictions_to: /tmp/test_softmax_outputs.txt
batch_size: 700 #set to number of rows of test file to test whole file

